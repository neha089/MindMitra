{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10848371,"sourceType":"datasetVersion","datasetId":6737407}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the CSV file from Kaggleâ€™s storage\ncsv_file = \"/kaggle/input/labeled-dataset/correct_dataset_sorted.csv\"  # Update dataset name\ndf = pd.read_csv(csv_file)\n\n# Group by 'tag' column\ngrouped = df.groupby(\"tag\")\n\ntrain_data = []\nvalidation_data = []\ntest_data = []\n\nfor tag, group in grouped:\n    patterns = group[\"pattern\"].tolist()\n    responses = group[\"response\"].tolist()\n\n    if len(patterns) > 1:\n        # Split into training (80%) and temp (20%)\n        train_patterns, temp_patterns, train_responses, temp_responses = train_test_split(\n            patterns, responses, train_size=0.8, random_state=42\n        )\n\n        if len(temp_patterns) > 1:\n            # Split remaining into validation (50%) and test (50%)\n            validation_patterns, test_patterns, validation_responses, test_responses = train_test_split(\n                temp_patterns, temp_responses, train_size=0.5, random_state=42\n            )\n        else:\n            validation_patterns, test_patterns = temp_patterns, []\n            validation_responses, test_responses = temp_responses, []\n\n        # Add to respective lists\n        train_data.extend([{\"tag\": tag, \"pattern\": p, \"response\": r} for p, r in zip(train_patterns, train_responses)])\n        validation_data.extend([{\"tag\": tag, \"pattern\": p, \"response\": r} for p, r in zip(validation_patterns, validation_responses)])\n        test_data.extend([{\"tag\": tag, \"pattern\": p, \"response\": r} for p, r in zip(test_patterns, test_responses)])\n    else:\n        # If only one pattern exists for a tag, add it to training data\n        train_data.append({\"tag\": tag, \"pattern\": patterns[0], \"response\": responses[0]})\n\ntrain_df = pd.DataFrame(train_data)\nvalidation_df = pd.DataFrame(validation_data)\ntest_df = pd.DataFrame(test_data)\n\n# Save in Kaggle's output folder (since /kaggle/input is read-only)\ntrain_df.to_csv(\"/kaggle/working/train_data.csv\", index=False, encoding='utf-8-sig')\nvalidation_df.to_csv(\"/kaggle/working/validation_data.csv\", index=False, encoding='utf-8-sig')\ntest_df.to_csv(\"/kaggle/working/test_data.csv\", index=False, encoding='utf-8-sig')\n\nprint(f\"Train Data saved: {len(train_df)} samples\")\nprint(f\"Validation Data saved: {len(validation_df)} samples\")\nprint(f\"Test Data saved: {len(test_df)} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T08:32:01.391327Z","iopub.execute_input":"2025-02-25T08:32:01.391738Z","iopub.status.idle":"2025-02-25T08:32:25.078581Z","shell.execute_reply.started":"2025-02-25T08:32:01.391708Z","shell.execute_reply":"2025-02-25T08:32:25.077313Z"}},"outputs":[{"name":"stdout","text":"Train Data saved: 645665 samples\nValidation Data saved: 80709 samples\nTest Data saved: 80711 samples\n","output_type":"stream"}],"execution_count":2}]}